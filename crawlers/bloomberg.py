from newspaper import Article
import requests
from bs4 import BeautifulSoup as bs


def crawlerUol():
    urls = ['https://www.bloomberg.com.br/blog/']

    print('---------------------------------------------')
    print("bloomberg.com.br")
    print('---------------------------------------------')

    for url in urls:
        print("EndereÃ§o principal -> ", url)
        print("")

        p = requests.get(url)
        s = bs(p.content, 'html.parser')

        newsurl = s.select('h2 a[href]')

        for singlenews in newsurl:
            newsurl = singlenews['href']
            article = Article(newsurl)
            article.download()
            article.parse()
            print("Data de publicacao: ", article.publish_date)
            print("Titulo: ", article.title)
            print("Link: ", newsurl)
            print("")

        print('---------------------------------------------')


crawlerUol()